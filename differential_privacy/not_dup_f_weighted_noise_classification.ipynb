{"cells":[{"cell_type":"markdown","metadata":{"id":"d9GnJBMbztj8"},"source":["# Applying Machine Learning Models"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1666077599221,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"YDF4vw-fztj-"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import itertools\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from datetime import datetime\n","\n","from sklearn import linear_model\n","# metrics: 計測 → 評価\n","from sklearn import metrics\n","\n","from sklearn.model_selection import GridSearchCV\n","# カーネルなしSVM（SVC: Support Vector Classifierの略）\n","from sklearn.svm import LinearSVC\n","# カーネル法を用いたSVM\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1813,"status":"ok","timestamp":1666093901044,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"z_zqrUgZZUYB","outputId":"0999f111-1c98-42e1-ba22-7763bf3ba4a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(9233, 642)\n"]}],"source":["data1 = pd.read_csv('Data_UCI_not_noise_1.csv')\n","data2 = pd.read_csv('Data_UCI_not_noise_2.csv')\n","\n","df_concat = pd.concat([data1, data2])\n","\n","print(df_concat.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"jK4L2ogo6zXA","outputId":"e618d39c-5d5f-487c-afc7-aa5ceb54b307"},"outputs":[],"source":["features_act = list()\n","features_uid = list()\n","\n","with open('act_feature_importance.txt', 'r') as f:\n","    features_act = f.read().splitlines()\n","\n","with open('uid_feature_importance.txt', 'r') as f:\n","    features_uid = f.read().splitlines()\n","\n","# print(features_act)\n","# print(features_uid)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"-cbAim_GcDDN"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","def split_train_test_data(df, id):\n","  X = df.drop(['user_Id', 'activity_Id'], axis=1)\n","  y = df[id]\n","\n","  return train_test_split(X, y, test_size=0.33, random_state=42) # X_train, X_test, y_train, y_test\n","\n","  # for i in X_train.columns:\n","  #   print(X_train[i].dtype)\n","  # print(X_train.dtypes)\n","\n","  # # 訓練用\n","  # X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n","  # y_train = train['subject']\n","\n","  # # テスト用\n","  # X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n","  # y_test = test['subject']\n","\n","  # print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n","  # print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"1dWE12XiztkB"},"source":["Let's make a function to plot the confusion matrix"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"8QTV20ztztkB"},"outputs":[],"source":["plt.rcParams['font.family'] = 'DejaVu Sans'\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n","    \n","    # normalize → 正規化\n","    if normalize:\n","        # cmの値は予測結果と実際の値の一致数なので，それを列の合計で割ると確率\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # np.newaxisは次元を追加\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    \n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        # plt.text(): 座標（x, y），表示するテキスト，文字位置，色指定\n","        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n","    \n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"]},{"cell_type":"markdown","metadata":{"id":"Qtj-5lXyztkB"},"source":["Let's make a function to run any model specified"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"UMHjny0sztkC"},"outputs":[],"source":["# 任意のモデルを実行\n","def perform_model_epsilon(model, X_train, y_train, X_test, y_test, class_labels, cm_nomalize=True, print_cm=True, cm_cmap=plt.cm.Greens):\n","    \n","    # to store results at various phases\n","    results = dict()\n","    \n","    # time at which model starts training \n","    train_start_time = datetime.now()\n","    print('training the model...')\n","    model.fit(X_train, y_train)\n","    print('Done')\n","    train_end_time = datetime.now()\n","    results['training_time'] = train_end_time - train_start_time\n","    print('==> training time:- {}\\n'.format(results['training_time']))\n","    \n","    # predict test data\n","    print('Predicting test data')\n","    test_start_time = datetime.now()\n","    y_pred = model.predict(X_test)\n","    test_end_time = datetime.now()\n","    results['testing_time'] = test_end_time - test_start_time\n","    print('==> testing time:- {}\\n'.format(results['testing_time']))\n","    # 予測結果を格納\n","    results['predicted'] = y_pred\n","    \n","    # calculate overall accuracy of the model\n","    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n","    # store accuracy in results\n","    results['accuracy'] = accuracy\n","    print('==> Accuracy:- {}\\n'.format(accuracy))\n","    \n","    # confusion matrix\n","    cm = metrics.confusion_matrix(y_test, y_pred)\n","    results['confusion_matrix'] = cm\n","    # output confusion matrix\n","    if print_cm:\n","        print('\\n ********Confusion Matrix********')\n","        print('\\n {}'.format(cm))\n","    \n","    # plot confusion matrix\n","    plt.figure(figsize=(15, 15))\n","    plt.grid(b=False) # グリッドを非表示\n","    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized Confusion Matrix', cmap = cm_cmap)\n","    plt.show()\n","    \n","    # get classification report\n","    # print('****************| Classifiction Report |****************')\n","    # classification_report = metrics.classification_report(y_test, y_pred)\n","    \n","    # # store report in results\n","    # results['classification_report'] = classification_report\n","    # print(classification_report)\n","    \n","    # get f1 score\n","    f1 = metrics.f1_score(y_test, y_pred, average=\"macro\")\n","    print(\"\\n F1 Score:{}\".format(f1))\n","    \n","    # add the trained model to the results\n","    results['model'] = model\n","    \n","    return results, f1\n","    "]},{"cell_type":"markdown","metadata":{"id":"rSSBk5dyztkC"},"source":["Make function to print the gridsearch Parameters"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"hXXnVumOztkD"},"outputs":[],"source":["# 同一モデルでの値を表示\n","def print_grid_search_attributes(model):\n","    \n","    # Estimator that gave highest score among all the estimators formed in GridSearch\n","    print('\\n\\n==> Best Estimator:')\n","    print('\\t{}\\n'.format(model.best_estimator_))\n","    \n","    # parameters that gave best results while perfoming grid search\n","    print('\\n==> Best parameters:')\n","    print('\\tParameters of best estimator : {}'.format(model.best_params_))\n","    \n","    # number of cross validation splits\n","    print('\\n==> No. of CrossValidation sets:')\n","    print('\\tTotal nmber of cross validation sets: {}'.format(model.n_splits_))\n","    \n","    # Average cross validated score of the best estimator, from the Grid Search\n","    print('\\n==> Best Score:')\n","    print('\\tAverage Cross Validate scores of Best estimator : {}'.format(model.best_score_))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666093901045,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"qI03h0T56DhI"},"outputs":[],"source":["labels_act = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n","\n","labels_uid = list()\n","for i in range(1, 31):\n","    labels_uid.append(i)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1666093926861,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"Nig36Y0TjK5J","outputId":"720ae144-779d-46e0-97c7-2cde46f0ba56"},"outputs":[{"name":"stdout","output_type":"stream","text":["111\n"]}],"source":["n = 211\n","f_add_weighted_noise = set()\n","for f in features_uid[:n]:\n","  # 重複していないものを入れる\n","  if f not in features_act[:n]:\n","    f_add_weighted_noise.add(f)\n","print(len(f_add_weighted_noise))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1666093948228,"user":{"displayName":"Ryusei Fujimoto","userId":"00131692607297579166"},"user_tz":-540},"id":"2N0j4lrhmsko"},"outputs":[],"source":["weighted_epsilon_array = [0.001, 0.005, 0.008, 0.01, 0.015, 0.02, 0.03, 0.04, 0.05]\n","weighted_epsilon = weighted_epsilon_array[1]"]},{"cell_type":"markdown","metadata":{"id":"8HPtUoULMh10"},"source":["## 2. Random Forest Classifier"]},{"cell_type":"markdown","metadata":{"id":"bTETiJB5OCs6"},"source":["## UID"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"icS8VaayOBN2"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------\n","epsilon:  1.0\n","--------\n","training the model...\n","Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"]}],"source":["import warnings\n","# 収束しなかった場合のwarning\n","from sklearn.exceptions import ConvergenceWarning\n","# warningを無視する\n","warnings.filterwarnings('ignore')\n","warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n","\n","# epsilons = [0.01, 0.05, 0.1, 0.3, 0.5, 1.0, 1.5, 2.0, 2.5, 3, 4, 5]\n","acc_array_random_uid = list()\n","\n","\n","epsilons = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0, 2.2, 2.5]\n","\n","for epsilon in epsilons:\n","\n","  print('--------')\n","  print('epsilon:  '+ str(epsilon))\n","  print('--------')\n","\n","  X_train, X_test, y_train, y_test = split_train_test_data(df_concat, 'user_Id')\n","\n","  for col in X_train:\n","      # default sensitivity = 1.0\n","    if col not in f_add_weighted_noise:\n","      # print(\"------epsilon--------\")\n","      # display(X_train[col].head())\n","      X_train[col] = X_train[col].apply(lambda x: x + np.random.laplace(0, 1.0/epsilon))\n","      X_test[col] = X_test[col].apply(lambda x: x + np.random.laplace(0, 1.0/epsilon))\n","      # display(X_train[col].head)\n","    else:\n","      # print(\"------weighted_epsilon--------\")\n","      # display(X_train[col].head())\n","      X_train[col] = X_train[col].apply(lambda x: x + np.random.laplace(0, 1.0/weighted_epsilon))\n","      X_test[col] = X_test[col].apply(lambda x: x + np.random.laplace(0, 1.0/weighted_epsilon))\n","      # display(X_train[col].head())\n","  \n","  params = {'n_estimators': np.arange(120,201,20), 'max_depth':np.arange(6,15,2)}\n","  rfc = RandomForestClassifier()\n","  rfc_grid = GridSearchCV(rfc, param_grid=params, cv=5, verbose=1, n_jobs=-1)\n","  rfc_grid_results, f1 = perform_model_epsilon(rfc_grid,  X_train.values, y_train.values, X_test.values, y_test.values, class_labels=labels_uid)\n","  acc_array_random_uid.append(rfc_grid_results['accuracy'])\n","  \n","  # observe the attributes of the model \n","  print_grid_search_attributes(rfc_grid_results['model'])\n","    \n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(epsilons[::-1], acc_array_random_uid[::-1], label='Random Forest in Noise')\n","ax.set_xlabel('epsilon')\n","ax.set_ylabel('accuracy')\n","plt.legend(loc='best')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# HAR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import warnings\n","# 収束しなかった場合のwarning\n","from sklearn.exceptions import ConvergenceWarning\n","# warningを無視する\n","warnings.filterwarnings('ignore')\n","warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n","\n","# epsilons = [0.01, 0.05, 0.1, 0.3, 0.5, 1.0, 1.5, 2.0, 2.5, 3, 4, 5]\n","acc_array_random_har = list()\n","\n","\n","epsilons = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0, 2.2, 2.5]\n","\n","for epsilon in epsilons:\n","\n","  print('--------')\n","  print('epsilon:  '+ str(epsilon))\n","  print('--------')\n","\n","  X_train, X_test, y_train, y_test = split_train_test_data(df_concat, 'activity_Id')\n","\n","  for col in X_train:\n","      # default sensitivity = 1.0\n","    if col not in f_add_weighted_noise:\n","      # print(\"------epsilon--------\")\n","      # display(X_train[col].head())\n","      X_train[col] = X_train[col].apply(lambda x: x + np.random.laplace(0, 1.0/epsilon))\n","      X_test[col] = X_test[col].apply(lambda x: x + np.random.laplace(0, 1.0/epsilon))\n","      # display(X_train[col].head)\n","    else:\n","      # print(\"------weighted_epsilon--------\")\n","      # display(X_train[col].head())\n","      X_train[col] = X_train[col].apply(lambda x: x + np.random.laplace(0, 1.0/weighted_epsilon))\n","      X_test[col] = X_test[col].apply(lambda x: x + np.random.laplace(0, 1.0/weighted_epsilon))\n","      # display(X_train[col].head())\n","    \n","  params = {'n_estimators': np.arange(120,201,20), 'max_depth':np.arange(6,15,2)}\n","  rfc = RandomForestClassifier()\n","  rfc_grid = GridSearchCV(rfc, param_grid=params, cv=5, verbose=1, n_jobs=-1)\n","  rfc_grid_results, f1 = perform_model_epsilon(rfc_grid, X_train.values, y_train.values, X_test.values, y_test.values, class_labels=labels_act)\n","  acc_array_random_har.append(rfc_grid_results['accuracy'])\n","  \n","  # observe the attributes of the model \n","  print_grid_search_attributes(rfc_grid_results['model'])\n","    \n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(epsilons[::-1], acc_array_random_har[::-1], label='Random Forest in Noise')\n","ax.set_xlabel('epsilon')\n","ax.set_ylabel('accuracy')\n","plt.legend(loc='best')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fy9TbVQuuO1M"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.603216278306531, 0.6192976698391861, 0.6435838529701345, 0.6465375779455201, 0.6809977026583525, 0.7006892024942566, 0.741384968821792, 0.7653429602888087, 0.7702658352477847, 0.799803085001641]\n","[0.04069576632753528, 0.05054151624548736, 0.05612077453232688, 0.060715457827371186, 0.08139153265507056, 0.06892024942566459, 0.1043649491302921, 0.11224154906465376, 0.13685592385953396, 0.1545782737118477]\n"]}],"source":["# epsilons = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0, 2.2, 2.5]\n","print(acc_array_random_har)\n","print(acc_array_random_uid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.005\n"]}],"source":["print(weighted_epsilon)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIE3NQ9VztkH"},"outputs":[],"source":["def beep():\n","  from google.colab import output\n","  output.eval_js('new Audio(\\\n","\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",".play()')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWvCZ6tBdmDm"},"outputs":[],"source":["# beep()"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"9cf94c4db506e4a0ca4ebab029940422049a9be7b0bda48bd1038b6fecafe843"}}},"nbformat":4,"nbformat_minor":0}
